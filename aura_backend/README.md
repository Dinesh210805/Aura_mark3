# AURA Backend Agent

## ğŸš€ What's New in AURA

### Intelligent Auto Model Selection (Like Cursor & Perplexity)
AURA now features **smart auto model selection** that analyzes your tasks and automatically chooses the best AI model for optimal performance, quality, and cost. No more manual model selection needed!

**Key Features:**
- ğŸ§  **Task Complexity Analysis**: Automatically detects simple vs complex tasks
- âš¡ **Performance Modes**: Speed, Balanced, Quality, and Cost optimization
- ğŸ’° **Cost Intelligence**: Uses cheaper models for simple tasks, premium for complex
- ğŸ¯ **Specialized Detection**: Auto-selects coding, vision, reasoning, or translation models
- ğŸ“Š **Latest Models**: Updated with Gemini 2.5 Pro, Flash, and Flash-Lite (July 2025)

### Multi-Provider Support
- **Groq**: Fast STT, LLM, VLM, TTS services
- **Gemini**: Advanced reasoning with 2M+ token context windows
- **Auto-Failover**: Seamless switching if providers are unavailable

## Setup Instructions

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Environment Variables
Copy `.env.example` to `.env` and fill in your API keys:
```bash
cp .env.example .env
```

Edit `.env`:
```
GROQ_API_KEY=your_groq_api_key_here
# PlayAI TTS is accessed through Groq API using playai-tts model
```

### 3. Run the Backend
```bash
python run.py
```

The server will start at `http://localhost:8000`

## API Endpoints

### Process Voice Request
**POST** `/process`
- Upload audio file and optional screenshot
- Returns action plan and TTS audio

### Text Chat
**POST** `/chat`
- Send text directly (for testing)
- Returns text response

### Health Check
**GET** `/health`
- Check service status

### API Documentation
- Interactive docs: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## ğŸ“š Documentation

- **[Auto Model Selection Guide](AUTO_MODEL_SELECTION_GUIDE.md)** - Complete guide to intelligent model selection
- **[Multi-Provider Guide](MULTI_PROVIDER_GUIDE.md)** - Provider switching and model management
- **[Auto Mode Guide](AUTO_MODE_GUIDE.md)** - Automated operation features

## Testing

### Test Auto Model Selection
```bash
# Test intelligent model selection
python test_auto_selection.py

# Test multi-provider functionality  
python test_multi_provider.py

# Test automated operations
python test_auto_mode.py
```

### Using curl
```bash
# Process voice + screenshot
curl -X POST http://localhost:8000/process \
  -F "audio=@sample.wav" \
  -F "screenshot=@screen.png" \
  -F "session_id=test-session-1"

# Text-only chat
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"text": "Open settings", "session_id": "test"}'
```

## Architecture

```
Android App â†â†’ FastAPI Backend â†â†’ LangGraph Agent â†â†’ Groq APIs
```

### LangGraph Flow
1. **STT Node** - Groq Whisper speech-to-text
2. **Intent Node** - LLM intent classification  
3. **UI Check Node** - Analyze accessibility tree
4. **VLM Node** - Vision analysis if needed
5. **Action Planner** - Create action sequence
6. **TTS Node** - Generate response audio

## Project Structure
```
aura_backend/
â”œâ”€â”€ main.py                    # FastAPI entrypoint
â”œâ”€â”€ aura_graph.py             # LangGraph pipeline
â”œâ”€â”€ run.py                    # Startup script
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ nodes/                   # LangGraph nodes
â”‚   â”œâ”€â”€ stt_node.py
â”‚   â”œâ”€â”€ intent_node.py
â”‚   â”œâ”€â”€ ui_check_node.py
â”‚   â”œâ”€â”€ vlm_node.py
â”‚   â”œâ”€â”€ action_planner_node.py
â”‚   â””â”€â”€ tts_node.py
â”œâ”€â”€ groq/                    # API integrations
â”‚   â”œâ”€â”€ stt.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ vlm.py
â”‚   â””â”€â”€ tts.py
â”œâ”€â”€ models/                  # Pydantic models
â”‚   â”œâ”€â”€ request_models.py
â”‚   â””â”€â”€ action_plan.py
â””â”€â”€ utils/                   # Utilities
    â””â”€â”€ image_utils.py
```

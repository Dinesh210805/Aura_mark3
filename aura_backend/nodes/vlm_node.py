# Generated by Copilot
from ai_services import vlm_service
import logging
import time
import os

logger = logging.getLogger(__name__)

class VLMNode:
    """Vision-Language Model node for UI element detection"""
    
    def __init__(self):
        self.name = "vlm"
    
    async def run(self, state: dict) -> dict:
        """Use VLM to locate UI elements on screen"""
        start_time = time.time()
        logger.info("VLM Node: Starting vision-language model analysis")
        
        screenshot = state.get("_screenshot_bytes")
        intent = state.get("intent", "")
        
        # Check if screenshot is available
        if not screenshot:
            logger.error("VLM Node: No screenshot data available")
            return {
                **state,
                "error": "No screenshot data available for VLM analysis",
                "node_execution_times": {
                    **state.get("node_execution_times", {}),
                    self.name: time.time() - start_time
                }
            }
            
        try:
            # Use VLM to locate UI elements with auto selection or configurable provider/model
            prefs = state.get("provider_preferences", {}).get("vlm", {})
            provider = prefs.get("provider") or os.getenv("VLM_PROVIDER", None)
            model = prefs.get("model") or os.getenv("VLM_MODEL", None)
            
            # Enable auto mode if no specific provider/model specified
            auto_mode = not provider and not model
            performance_mode = prefs.get("performance_mode", "balanced")
            cost_sensitive = prefs.get("cost_sensitive", True)
            
            vlm_result = await vlm_service.locate_ui_element(
                screenshot, 
                intent,
                provider=provider,
                model=model,
                auto_mode=auto_mode,
                performance_mode=performance_mode,
                cost_sensitive=cost_sensitive
            )
            
            # Check if VLM found the element
            if vlm_result.get("found"):
                logger.info(f"VLM Node: Successfully located UI element - {vlm_result.get('element_description', 'Unknown')}")
                
                return {
                    **state,
                    "ui_element_coords": vlm_result.get("coordinates"),
                    "vlm_confidence": vlm_result.get("confidence", 0.5),
                    "element_description": vlm_result.get("element_description"),
                    "vlm_reasoning": vlm_result.get("reasoning"),
                    "node_execution_times": {
                        **state.get("node_execution_times", {}),
                        self.name: time.time() - start_time
                    }
                }
            else:
                logger.warning("VLM Node: Could not locate UI element")
                error_msg = vlm_result.get("error", "UI element not found by VLM")
                
                return {
                    **state,
                    "error": error_msg,
                    "vlm_attempted": True,
                    "node_execution_times": {
                        **state.get("node_execution_times", {}),
                        self.name: time.time() - start_time
                    }
                }
                
        except Exception as e:
            logger.error(f"VLM Node error: {str(e)}")
            return {
                **state,
                "error": f"VLM processing failed: {str(e)}",
                "vlm_attempted": True,
                "node_execution_times": {
                    **state.get("node_execution_times", {}),
                    self.name: time.time() - start_time
                }
            }

# Create node instance
vlm_node = VLMNode()

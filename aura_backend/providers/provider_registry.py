# Generated by Copilot
"""
Provider Registry for Dynamic AI Provider Management
Manages multiple AI providers with automatic failover and load balancing
Enhanced with intelligent auto model selection
"""

import os
import asyncio
from typing import Dict, List, Optional, Any, Union, Type
from dataclasses import dataclass, field
from enum import Enum
import logging

from .base import (
    BaseSTTProvider, BaseLLMProvider, BaseVLMProvider, BaseTTSProvider,
    AIModel, ProviderConfig, ProviderError, ModelNotAvailableError,
    ProviderUnavailableError, RateLimitError
)
from .groq_provider import GroqProvider
from .gemini_provider import GeminiProvider
from .auto_model_selector import auto_selector, TaskComplexity, PerformanceMode

logger = logging.getLogger(__name__)

class ServiceType(Enum):
    """AI service types"""
    STT = "stt"
    LLM = "llm" 
    VLM = "vlm"
    TTS = "tts"

@dataclass
class ProviderPriority:
    """Provider priority configuration"""
    provider_name: str
    priority: int = 0  # Higher number = higher priority
    max_requests_per_minute: Optional[int] = None
    cost_multiplier: float = 1.0
    enabled: bool = True

@dataclass
class ServiceConfig:
    """Configuration for a specific service type"""
    service_type: ServiceType
    default_provider: str
    fallback_providers: List[str] = field(default_factory=list)
    default_model: Optional[str] = None
    provider_priorities: List[ProviderPriority] = field(default_factory=list)
    enable_fallback: bool = True
    timeout: float = 30.0

class ProviderRegistry:
    """
    Central registry for managing multiple AI providers
    Handles provider selection, failover, and load balancing
    """
    
    def __init__(self):
        self.providers: Dict[str, Any] = {}
        self.service_configs: Dict[ServiceType, ServiceConfig] = {}
        self._initialize_providers()
        self._setup_default_configs()
    
    def _initialize_providers(self):
        """Initialize all available providers"""
        
        # Initialize Groq provider
        groq_config = ProviderConfig(
            name="groq",
            api_key=os.getenv("GROQ_API_KEY", ""),
            base_url="https://api.groq.com/openai/v1",
            timeout=30.0,
            max_retries=3,
            default_models={
                "stt": "whisper-large-v3-turbo",
                "llm": "llama-3.3-70b-versatile", 
                "vlm": "llama-4-maverick-17b-128e-instruct",
                "tts": "playai-tts"
            }
        )
        
        if groq_config.api_key:
            self.providers["groq"] = GroqProvider(groq_config)
            logger.info("Groq provider initialized")
        else:
            logger.warning("Groq API key not found, provider disabled")
        
        # Initialize Gemini provider
        gemini_config = ProviderConfig(
            name="gemini",
            api_key=os.getenv("GEMINI_API_KEY", ""),
            base_url="https://generativelanguage.googleapis.com/v1beta",
            timeout=30.0,
            max_retries=3,
            default_models={
                "llm": "gemini-1.5-flash",     # Stable, fast model
                "vlm": "gemini-1.5-flash"      # Stable, fast model
            }
        )
        
        if gemini_config.api_key:
            self.providers["gemini"] = GeminiProvider(gemini_config)
            logger.info("Gemini provider initialized")
        else:
            logger.warning("Gemini API key not found, provider disabled")
    
    def _setup_default_configs(self):
        """Setup default service configurations"""
        
        # STT Service Configuration
        self.service_configs[ServiceType.STT] = ServiceConfig(
            service_type=ServiceType.STT,
            default_provider="groq",  # Only Groq supports STT
            fallback_providers=[],
            default_model="whisper-large-v3-turbo"
        )
        
        # LLM Service Configuration  
        self.service_configs[ServiceType.LLM] = ServiceConfig(
            service_type=ServiceType.LLM,
            default_provider=os.getenv("DEFAULT_LLM_PROVIDER", "groq"),
            fallback_providers=["gemini", "groq"],
            default_model=os.getenv("DEFAULT_LLM_MODEL"),
            provider_priorities=[
                ProviderPriority("groq", priority=1, cost_multiplier=1.0),
                ProviderPriority("gemini", priority=2, cost_multiplier=1.2)
            ]
        )
        
        # VLM Service Configuration
        self.service_configs[ServiceType.VLM] = ServiceConfig(
            service_type=ServiceType.VLM,
            default_provider=os.getenv("DEFAULT_VLM_PROVIDER", "groq"),
            fallback_providers=["gemini", "groq"],
            default_model=os.getenv("DEFAULT_VLM_MODEL"),
            provider_priorities=[
                ProviderPriority("groq", priority=1, cost_multiplier=1.0),
                ProviderPriority("gemini", priority=2, cost_multiplier=0.8)  # Gemini might be cheaper
            ]
        )
        
        # TTS Service Configuration
        self.service_configs[ServiceType.TTS] = ServiceConfig(
            service_type=ServiceType.TTS,
            default_provider="groq",  # Only Groq supports TTS
            fallback_providers=[],
            default_model="playai-tts"
        )
    
    def get_provider(
        self, 
        service_type: ServiceType, 
        provider_name: Optional[str] = None
    ) -> Optional[Any]:
        """Get provider for specific service type"""
        
        if provider_name:
            # Use specified provider
            if provider_name in self.providers:
                provider = self.providers[provider_name]
                if self._provider_supports_service(provider, service_type):
                    return provider
                else:
                    logger.warning(f"Provider {provider_name} doesn't support {service_type.value}")
                    return None
            else:
                logger.error(f"Provider {provider_name} not found")
                return None
        
        # Use default provider selection
        config = self.service_configs.get(service_type)
        if not config:
            logger.error(f"No configuration found for service type {service_type.value}")
            return None
        
        # Try default provider first
        if config.default_provider in self.providers:
            provider = self.providers[config.default_provider]
            if provider.is_available() and self._provider_supports_service(provider, service_type):
                return provider
        
        # Try fallback providers
        for fallback_provider in config.fallback_providers:
            if fallback_provider in self.providers:
                provider = self.providers[fallback_provider]
                if provider.is_available() and self._provider_supports_service(provider, service_type):
                    logger.info(f"Using fallback provider {fallback_provider} for {service_type.value}")
                    return provider
        
        logger.error(f"No available provider found for service type {service_type.value}")
        return None
    
    def _provider_supports_service(self, provider: Any, service_type: ServiceType) -> bool:
        """Check if provider supports the service type"""
        if service_type == ServiceType.STT:
            return isinstance(provider, BaseSTTProvider)
        elif service_type == ServiceType.LLM:
            return isinstance(provider, BaseLLMProvider)
        elif service_type == ServiceType.VLM:
            return isinstance(provider, BaseVLMProvider)
        elif service_type == ServiceType.TTS:
            return isinstance(provider, BaseTTSProvider)
        return False
    
    async def execute_with_fallback(
        self,
        service_type: ServiceType,
        method_name: str,
        provider_name: Optional[str] = None,
        model: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Execute AI service method with automatic fallback
        """
        config = self.service_configs.get(service_type)
        if not config:
            return {"success": False, "error": f"No configuration for {service_type.value}"}
        
        # Determine providers to try
        providers_to_try = []
        
        if provider_name:
            # Use specified provider only
            if provider_name in self.providers:
                providers_to_try = [provider_name]
            else:
                return {"success": False, "error": f"Provider {provider_name} not found"}
        else:
            # Use default + fallbacks
            providers_to_try = [config.default_provider] + config.fallback_providers
            # Remove duplicates while preserving order
            providers_to_try = list(dict.fromkeys(providers_to_try))
        
        last_error = None
        
        for provider_name in providers_to_try:
            if provider_name not in self.providers:
                continue
                
            provider = self.providers[provider_name]
            
            if not provider.is_available():
                logger.warning(f"Provider {provider_name} not available")
                continue
                
            if not self._provider_supports_service(provider, service_type):
                logger.warning(f"Provider {provider_name} doesn't support {service_type.value}")
                continue
            
            try:
                # Get the method to call
                if not hasattr(provider, method_name):
                    logger.warning(f"Provider {provider_name} doesn't have method {method_name}")
                    continue
                
                method = getattr(provider, method_name)
                
                # Use provider's default model if none specified
                if not model and hasattr(provider.config, 'default_models'):
                    model = provider.config.default_models.get(service_type.value)
                
                # Execute the method
                logger.info(f"Executing {method_name} on {provider_name} with model {model}")
                
                if asyncio.iscoroutinefunction(method):
                    if model:
                        result = await method(model=model, **kwargs)
                    else:
                        result = await method(**kwargs)
                else:
                    if model:
                        result = method(model=model, **kwargs)
                    else:
                        result = method(**kwargs)
                
                # Check if result indicates success
                if self._is_successful_result(result, service_type):
                    logger.info(f"Successfully executed {method_name} on {provider_name}")
                    return {
                        "success": True,
                        "result": result,
                        "provider_used": provider_name,
                        "model_used": model
                    }
                else:
                    logger.warning(f"Method {method_name} on {provider_name} returned unsuccessful result")
                    last_error = f"Provider {provider_name} returned unsuccessful result"
                    
            except RateLimitError as e:
                logger.warning(f"Rate limit hit on {provider_name}, trying next provider")
                last_error = str(e)
                continue
                
            except ProviderUnavailableError as e:
                logger.warning(f"Provider {provider_name} unavailable: {str(e)}")
                last_error = str(e)
                continue
                
            except Exception as e:
                logger.error(f"Error executing {method_name} on {provider_name}: {str(e)}")
                last_error = str(e)
                
                # Don't continue to fallback for certain errors
                if not config.enable_fallback:
                    break
                    
                continue
        
        # All providers failed
        return {
            "success": False,
            "error": last_error or f"All providers failed for {service_type.value}",
            "providers_tried": providers_to_try
        }
    
    def _is_successful_result(self, result: Any, service_type: ServiceType) -> bool:
        """Check if result indicates success"""
        if result is None:
            return False
            
        if isinstance(result, dict):
            # For methods that return dict with success/error indicators
            if "error" in result:
                return False
            if "success" in result:
                return result["success"]
            if service_type == ServiceType.VLM and "found" in result:
                return result["found"]
                
        if isinstance(result, str):
            # For methods that return string (like transcribe, generate_response)
            return bool(result.strip())
            
        if isinstance(result, bytes):
            # For methods that return bytes (like TTS)
            return len(result) > 0
        
        # Default: assume non-None result is successful
        return True
    
    async def execute_with_auto_selection(
        self,
        service_type: ServiceType,
        method_name: str,
        text: str = "",
        context: Dict[str, Any] = None,
        performance_mode: str = "balanced",
        cost_sensitive: bool = True,
        auto_mode: bool = True,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Execute AI service method with intelligent auto model selection
        Falls back to manual selection if auto mode fails
        """
        provider_name = kwargs.pop("provider", None)
        model = kwargs.pop("model", None)
        
        # If auto mode is enabled and no explicit provider/model specified
        if auto_mode and not provider_name and not model:
            try:
                # Use auto selector to choose optimal provider and model
                auto_provider, auto_model = auto_selector.select_model(
                    service_type.value,
                    text=text,
                    context=context,
                    performance_mode=performance_mode,
                    cost_sensitive=cost_sensitive
                )
                
                if auto_provider and auto_model:
                    logger.info(f"Auto-selected {auto_provider}/{auto_model} for {service_type.value}")
                    
                    # Try the auto-selected combination first
                    result = await self.execute_with_fallback(
                        service_type=service_type,
                        method_name=method_name,
                        provider_name=auto_provider,
                        model=auto_model,
                        **kwargs
                    )
                    
                    if result.get("success"):
                        # Add auto selection metadata
                        result["auto_selected"] = True
                        result["selection_criteria"] = {
                            "provider": auto_provider,
                            "model": auto_model,
                            "performance_mode": performance_mode,
                            "cost_sensitive": cost_sensitive
                        }
                        return result
                    else:
                        logger.warning(f"Auto-selected model failed, falling back to default selection")
                        
                        # Try fallback models from auto selector
                        fallback_models = auto_selector.get_fallback_models(service_type.value, auto_provider)
                        for fallback_provider, fallback_model in fallback_models:
                            logger.info(f"Trying fallback: {fallback_provider}/{fallback_model}")
                            fallback_result = await self.execute_with_fallback(
                                service_type=service_type,
                                method_name=method_name,
                                provider_name=fallback_provider,
                                model=fallback_model,
                                **kwargs
                            )
                            
                            if fallback_result.get("success"):
                                fallback_result["auto_selected"] = True
                                fallback_result["fallback_used"] = True
                                return fallback_result
                        
            except Exception as e:
                logger.error(f"Auto selection failed: {str(e)}, falling back to default")
        
        # Fall back to normal execution with fallback
        return await self.execute_with_fallback(
            service_type=service_type,
            method_name=method_name,
            provider_name=provider_name,
            model=model,
            **kwargs
        )
    
    def get_auto_selection_recommendation(
        self,
        service_type: str,
        text: str = "",
        context: Dict[str, Any] = None,
        performance_mode: str = "balanced",
        cost_sensitive: bool = True
    ) -> Dict[str, Any]:
        """
        Get auto selection recommendation without executing
        Useful for UI/API to show what would be selected
        """
        try:
            provider, model = auto_selector.select_model(
                service_type,
                text=text,
                context=context,
                performance_mode=performance_mode,
                cost_sensitive=cost_sensitive
            )
            
            if provider and model:
                # Analyze the task for explanation
                criteria = auto_selector.analyze_task_complexity(text, context)
                explanation = auto_selector.explain_selection(service_type, provider, model, criteria)
                
                return {
                    "provider": provider,
                    "model": model,
                    "criteria": {
                        "complexity": criteria.task_complexity.value,
                        "performance_mode": criteria.performance_mode.value,
                        "context_length": criteria.context_length_needed,
                        "requires_coding": criteria.requires_coding,
                        "requires_reasoning": criteria.requires_reasoning,
                        "multimodal": criteria.has_images or criteria.has_audio,
                        "cost_sensitive": criteria.cost_sensitive
                    },
                    "explanation": explanation,
                    "fallback_options": auto_selector.get_fallback_models(service_type, provider)
                }
            else:
                return {"error": "No recommendation available"}
                
        except Exception as e:
            logger.error(f"Error getting auto selection recommendation: {str(e)}")
            return {"error": str(e)}
    
    def configure_auto_mode(
        self,
        enabled: bool = True,
        default_performance_mode: str = "balanced",
        cost_sensitivity: bool = True
    ) -> Dict[str, Any]:
        """
        Configure auto mode settings
        """
        try:
            # Store auto mode configuration
            if not hasattr(self, '_auto_config'):
                self._auto_config = {}
            
            self._auto_config.update({
                "enabled": enabled,
                "default_performance_mode": default_performance_mode,
                "cost_sensitivity": cost_sensitivity
            })
            
            logger.info(f"Auto mode configured: enabled={enabled}, mode={default_performance_mode}")
            
            return {
                "success": True,
                "config": self._auto_config
            }
            
        except Exception as e:
            logger.error(f"Error configuring auto mode: {str(e)}")
            return {"error": str(e)}
    
    def get_auto_mode_config(self) -> Dict[str, Any]:
        """Get current auto mode configuration"""
        if hasattr(self, '_auto_config'):
            return self._auto_config
        else:
            return {
                "enabled": True,
                "default_performance_mode": "balanced",
                "cost_sensitivity": True
            }

    async def health_check(self) -> Dict[str, Any]:
        """Check health of all providers"""
        health_status = {}
        
        for provider_name, provider in self.providers.items():
            try:
                status = await provider.health_check()
                health_status[provider_name] = status
            except Exception as e:
                health_status[provider_name] = {
                    "status": "error",
                    "error": str(e)
                }
        
        return {
            "overall_status": "healthy" if any(
                status.get("status") == "healthy" 
                for status in health_status.values()
            ) else "unhealthy",
            "providers": health_status
        }
    
    def get_available_models(
        self, 
        service_type: Optional[ServiceType] = None,
        provider_name: Optional[str] = None
    ) -> List[AIModel]:
        """Get available models for service type and/or provider"""
        models = []
        
        providers_to_check = []
        if provider_name:
            if provider_name in self.providers:
                providers_to_check = [self.providers[provider_name]]
        else:
            providers_to_check = list(self.providers.values())
        
        for provider in providers_to_check:
            provider_models = provider.get_available_models()
            
            if service_type:
                # Filter by service type
                provider_models = [
                    model for model in provider_models 
                    if service_type.value in model.capabilities
                ]
            
            models.extend(provider_models)
        
        return models
    
    def update_service_config(
        self, 
        service_type: ServiceType, 
        config: ServiceConfig
    ):
        """Update service configuration"""
        self.service_configs[service_type] = config
        logger.info(f"Updated configuration for {service_type.value}")
    
    def set_default_provider(
        self, 
        service_type: ServiceType, 
        provider_name: str
    ):
        """Set default provider for service type"""
        if service_type in self.service_configs:
            self.service_configs[service_type].default_provider = provider_name
            logger.info(f"Set default {service_type.value} provider to {provider_name}")
        else:
            logger.error(f"No configuration found for {service_type.value}")
    
    def set_default_model(
        self, 
        service_type: ServiceType, 
        model_name: str
    ):
        """Set default model for service type"""
        if service_type in self.service_configs:
            self.service_configs[service_type].default_model = model_name
            logger.info(f"Set default {service_type.value} model to {model_name}")
        else:
            logger.error(f"No configuration found for {service_type.value}")
    
    def get_provider_info(self) -> Dict[str, Any]:
        """Get information about all providers and their capabilities"""
        provider_info = {}
        
        for provider_name, provider in self.providers.items():
            models = provider.get_available_models()
            capabilities = set()
            for model in models:
                capabilities.update(model.capabilities)
            
            provider_info[provider_name] = {
                "available": provider.is_available(),
                "capabilities": list(capabilities),
                "models": [
                    {
                        "name": model.name,
                        "capabilities": model.capabilities,
                        "description": model.description
                    }
                    for model in models
                ]
            }
        
        return provider_info

# Global registry instance
provider_registry = ProviderRegistry()

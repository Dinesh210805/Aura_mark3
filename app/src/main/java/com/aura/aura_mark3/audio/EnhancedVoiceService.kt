// Generated by Copilot
package com.aura.aura_mark3.audio

import android.annotation.SuppressLint
import android.app.Notification
import android.app.NotificationChannel
import android.app.NotificationManager
import android.app.Service
import android.content.Intent
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.os.Build
import android.os.Handler
import android.os.IBinder
import android.os.Looper
import android.util.Log
import androidx.core.app.NotificationCompat
import com.aura.aura_mark3.ai.GroqSttApi
import com.aura.aura_mark3.ai.SttResponse
import com.aura.aura_mark3.ai.provideGroqSttApi
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import okhttp3.MultipartBody
import okhttp3.RequestBody.Companion.asRequestBody
import okhttp3.RequestBody.Companion.toRequestBody
import retrofit2.Call
import retrofit2.Callback
import retrofit2.Response
import java.io.File
import java.io.FileOutputStream
import java.util.concurrent.atomic.AtomicBoolean
import kotlin.math.sqrt

/**
 * Enhanced Voice Service with Continuous Listening and Wake Word Detection
 * 
 * Features:
 * - Continuous audio monitoring for "Hey Aura" wake word
 * - Voice Activity Detection (VAD) for efficient processing
 * - Automatic transcription when voice is detected
 * - Low power consumption with smart audio buffering
 * - Real-time audio level monitoring
 */
class EnhancedVoiceService : Service() {

    companion object {
        const val CHANNEL_ID = "AURA_VOICE_SERVICE"
        const val NOTIFICATION_ID = 2
        const val SAMPLE_RATE = 16000
        const val AUDIO_SOURCE = MediaRecorder.AudioSource.MIC
        const val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO
        const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        
        // Wake word detection parameters
        const val WAKE_WORD_TIMEOUT_MS = 5000L // 5 seconds to detect wake word
        const val VOICE_TIMEOUT_MS = 3000L     // 3 seconds of silence to stop recording
        const val AUDIO_LEVEL_THRESHOLD = 2000 // Minimum audio level for voice detection
        
        // Intent actions
        const val ACTION_WAKE_WORD_DETECTED = "com.aura.aura_mark3.WAKE_WORD_DETECTED"
        const val ACTION_VOICE_TRANSCRIPTION = "com.aura.aura_mark3.VOICE_TRANSCRIPTION"
        const val ACTION_LISTENING_STATE = "com.aura.aura_mark3.LISTENING_STATE"
        const val ACTION_AUDIO_LEVEL = "com.aura.aura_mark3.AUDIO_LEVEL"
        
        // Intent extras
        const val EXTRA_TRANSCRIPTION = "transcription"
        const val EXTRA_IS_LISTENING = "is_listening"
        const val EXTRA_AUDIO_LEVEL = "audio_level"
        const val EXTRA_LISTENING_TYPE = "listening_type" // "wake_word" or "command"
    }

    private var audioRecord: AudioRecord? = null
    private var recordingThread: Thread? = null
    private val isRunning = AtomicBoolean(false)
    private val isListeningForWakeWord = AtomicBoolean(true)
    private val isRecordingCommand = AtomicBoolean(false)
    
    private var currentAudioLevel = 0
    private var lastVoiceDetectedTime = 0L
    private var wakeWordDetectedTime = 0L
    
    private val audioBuffer = mutableListOf<Short>()
    private val maxBufferSize = SAMPLE_RATE * 10 // 10 seconds of audio
    
    private val mainHandler = Handler(Looper.getMainLooper())
    private val sttApi = provideGroqSttApi()
    
    // Audio processing variables
    private var silenceCounter = 0
    private val maxSilenceFrames = (VOICE_TIMEOUT_MS / 100).toInt() // 100ms frames
    
    override fun onCreate() {
        super.onCreate()
        createNotificationChannel()
        Log.i("EnhancedVoiceService", "Enhanced Voice Service created")
    }

    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int {
        if (!isRunning.get()) {
            startContinuousListening()
        }
        return START_STICKY
    }

    override fun onDestroy() {
        super.onDestroy()
        stopContinuousListening()
        Log.i("EnhancedVoiceService", "Enhanced Voice Service destroyed")
    }

    override fun onBind(intent: Intent?): IBinder? = null

    @SuppressLint("ObsoleteSdkInt")
    private fun createNotificationChannel() {
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            val channel = NotificationChannel(
                CHANNEL_ID,
                "AURA Voice Assistant",
                NotificationManager.IMPORTANCE_LOW
            ).apply {
                description = "Continuous voice monitoring for Hey Aura wake word"
                setSound(null, null)
                enableVibration(false)
            }
            
            val notificationManager = getSystemService(NotificationManager::class.java)
            notificationManager?.createNotificationChannel(channel)
        }
    }

    private fun buildNotification(isListening: Boolean, listeningType: String): Notification {
        val title = when {
            isListening && listeningType == "wake_word" -> "ðŸŽ¤ Listening for 'Hey Aura'"
            isListening && listeningType == "command" -> "ðŸ—£ï¸ Recording your command"
            else -> "ðŸ˜´ Voice assistant ready"
        }
        
        return NotificationCompat.Builder(this, CHANNEL_ID)
            .setContentTitle("AURA Voice Assistant")
            .setContentText(title)
            .setSmallIcon(android.R.drawable.ic_btn_speak_now)
            .setOngoing(true)
            .setSilent(true)
            .build()
    }

    @SuppressLint("MissingPermission")
    private fun startContinuousListening() {
        if (isRunning.get()) return
        
        try {
            val bufferSize = AudioRecord.getMinBufferSize(
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT
            ) * 2
            
            audioRecord = AudioRecord(
                AUDIO_SOURCE,
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT,
                bufferSize
            )
            
            if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
                Log.e("EnhancedVoiceService", "AudioRecord initialization failed")
                return
            }
            
            isRunning.set(true)
            audioRecord?.startRecording()
            
            // Start with wake word listening notification
            startForeground(NOTIFICATION_ID, buildNotification(true, "wake_word"))
            broadcastListeningState(true, "wake_word")
            
            recordingThread = Thread { processAudioStream() }.apply { start() }
            
            Log.i("EnhancedVoiceService", "Continuous listening started")
            
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Failed to start continuous listening", e)
            stopContinuousListening()
        }
    }

    private fun stopContinuousListening() {
        isRunning.set(false)
        isListeningForWakeWord.set(false)
        isRecordingCommand.set(false)
        
        try {
            audioRecord?.stop()
            audioRecord?.release()
            audioRecord = null
            
            recordingThread?.interrupt()
            recordingThread = null
            
            audioBuffer.clear()
            
            broadcastListeningState(false, "stopped")
            Log.i("EnhancedVoiceService", "Continuous listening stopped")
            
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error stopping continuous listening", e)
        }
    }

    private fun processAudioStream() {
        val buffer = ShortArray(1024)
        
        while (isRunning.get() && audioRecord?.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
            try {
                val bytesRead = audioRecord?.read(buffer, 0, buffer.size) ?: -1
                
                if (bytesRead > 0) {
                    val audioLevel = calculateAudioLevel(buffer, bytesRead)
                    currentAudioLevel = audioLevel
                    
                    // Broadcast audio level for UI feedback
                    broadcastAudioLevel(audioLevel)
                    
                    // Process based on current state
                    when {
                        isListeningForWakeWord.get() -> {
                            processWakeWordDetection(buffer, bytesRead, audioLevel)
                        }
                        isRecordingCommand.get() -> {
                            processCommandRecording(buffer, bytesRead, audioLevel)
                        }
                    }
                }
                
                Thread.sleep(10) // Small delay to prevent excessive CPU usage
                
            } catch (e: InterruptedException) {
                break
            } catch (e: Exception) {
                Log.e("EnhancedVoiceService", "Error in audio processing", e)
                break
            }
        }
    }

    private fun calculateAudioLevel(buffer: ShortArray, length: Int): Int {
        var sum = 0.0
        for (i in 0 until length) {
            sum += (buffer[i] * buffer[i]).toDouble()
        }
        return sqrt(sum / length).toInt()
    }

    private fun processWakeWordDetection(buffer: ShortArray, length: Int, audioLevel: Int) {
        if (audioLevel > AUDIO_LEVEL_THRESHOLD) {
            // Voice detected, add to buffer
            for (i in 0 until length) {
                audioBuffer.add(buffer[i])
            }
            
            // Maintain buffer size
            while (audioBuffer.size > maxBufferSize) {
                audioBuffer.removeAt(0)
            }
            
            lastVoiceDetectedTime = System.currentTimeMillis()
            
            // Check if we have enough audio for wake word detection
            if (audioBuffer.size >= SAMPLE_RATE * 2) { // 2 seconds of audio
                checkForWakeWord()
            }
        } else {
            // Silence detected, check timeout
            if (audioBuffer.isNotEmpty() && 
                System.currentTimeMillis() - lastVoiceDetectedTime > 1000) {
                // Clear buffer after 1 second of silence
                audioBuffer.clear()
            }
        }
    }

    private fun processCommandRecording(buffer: ShortArray, length: Int, audioLevel: Int) {
        if (audioLevel > AUDIO_LEVEL_THRESHOLD) {
            // Voice detected, add to buffer
            for (i in 0 until length) {
                audioBuffer.add(buffer[i])
            }
            lastVoiceDetectedTime = System.currentTimeMillis()
            silenceCounter = 0
        } else {
            // Silence detected
            silenceCounter++
            
            if (silenceCounter >= maxSilenceFrames) {
                // End of command detected
                finishCommandRecording()
            }
        }
    }

    private fun checkForWakeWord() {
        if (audioBuffer.isEmpty()) return
        
        // Simple wake word detection based on audio patterns
        // In a production app, you'd use a more sophisticated wake word detection library
        val audioData = audioBuffer.toShortArray()
        
        // Convert to WAV and check with STT for "hey aura" or similar patterns
        val tempFile = createTempAudioFile(audioData)
        if (tempFile != null) {
            transcribeForWakeWord(tempFile)
        }
        
        // Clear buffer after processing
        audioBuffer.clear()
    }

    private fun transcribeForWakeWord(audioFile: File) {
        try {
            val apiKey = loadApiKey()
            if (apiKey.isBlank()) {
                Log.e("EnhancedVoiceService", "API key not found")
                return
            }
            
            val fileBody = audioFile.asRequestBody("audio/wav".toMediaTypeOrNull())
            val filePart = MultipartBody.Part.createFormData("file", audioFile.name, fileBody)
            val modelBody = "whisper-large-v3-turbo".toRequestBody("text/plain".toMediaTypeOrNull())
            
            sttApi.transcribeAudio("Bearer $apiKey", filePart, modelBody)
                .enqueue(object : Callback<SttResponse> {
                    override fun onResponse(call: Call<SttResponse>, response: Response<SttResponse>) {
                        if (response.isSuccessful) {
                            val transcription = response.body()?.text?.lowercase() ?: ""
                            Log.i("EnhancedVoiceService", "Wake word check: $transcription")
                            
                            // Check for wake words
                            if (transcription.contains("hey aura") || 
                                transcription.contains("aura") ||
                                transcription.contains("hey ora") ||
                                transcription.contains("hey aira")) {
                                
                                onWakeWordDetected()
                            }
                        } else {
                            Log.e("EnhancedVoiceService", "STT failed: ${response.code()}")
                        }
                        audioFile.delete()
                    }
                    
                    override fun onFailure(call: Call<SttResponse>, t: Throwable) {
                        Log.e("EnhancedVoiceService", "STT request failed", t)
                        audioFile.delete()
                    }
                })
                
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error in wake word transcription", e)
            audioFile.delete()
        }
    }

    private fun onWakeWordDetected() {
        Log.i("EnhancedVoiceService", "Wake word 'Hey Aura' detected!")
        
        // Switch to command recording mode
        isListeningForWakeWord.set(false)
        isRecordingCommand.set(true)
        wakeWordDetectedTime = System.currentTimeMillis()
        audioBuffer.clear()
        silenceCounter = 0
        
        // Update notification
        mainHandler.post {
            startForeground(NOTIFICATION_ID, buildNotification(true, "command"))
            broadcastListeningState(true, "command")
            
            // Broadcast wake word detection
            val intent = Intent(ACTION_WAKE_WORD_DETECTED)
            sendBroadcast(intent)
        }
    }

    private fun finishCommandRecording() {
        if (!isRecordingCommand.get()) return
        
        isRecordingCommand.set(false)
        
        Log.i("EnhancedVoiceService", "Command recording finished")
        
        if (audioBuffer.isNotEmpty()) {
            val audioData = audioBuffer.toShortArray()
            val tempFile = createTempAudioFile(audioData)
            
            if (tempFile != null) {
                transcribeCommand(tempFile)
            }
        }
        
        // Return to wake word listening
        audioBuffer.clear()
        isListeningForWakeWord.set(true)
        
        mainHandler.post {
            startForeground(NOTIFICATION_ID, buildNotification(true, "wake_word"))
            broadcastListeningState(true, "wake_word")
        }
    }

    private fun transcribeCommand(audioFile: File) {
        try {
            val apiKey = loadApiKey()
            if (apiKey.isBlank()) {
                Log.e("EnhancedVoiceService", "API key not found")
                audioFile.delete()
                return
            }
            
            val fileBody = audioFile.asRequestBody("audio/wav".toMediaTypeOrNull())
            val filePart = MultipartBody.Part.createFormData("file", audioFile.name, fileBody)
            val modelBody = "whisper-large-v3-turbo".toRequestBody("text/plain".toMediaTypeOrNull())
            
            sttApi.transcribeAudio("Bearer $apiKey", filePart, modelBody)
                .enqueue(object : Callback<SttResponse> {
                    override fun onResponse(call: Call<SttResponse>, response: Response<SttResponse>) {
                        if (response.isSuccessful) {
                            val transcription = response.body()?.text ?: ""
                            Log.i("EnhancedVoiceService", "Command transcription: $transcription")
                            
                            if (transcription.isNotBlank()) {
                                // Broadcast transcription
                                val intent = Intent(ACTION_VOICE_TRANSCRIPTION).apply {
                                    putExtra(EXTRA_TRANSCRIPTION, transcription)
                                }
                                sendBroadcast(intent)
                            }
                        } else {
                            Log.e("EnhancedVoiceService", "Command STT failed: ${response.code()}")
                        }
                        audioFile.delete()
                    }
                    
                    override fun onFailure(call: Call<SttResponse>, t: Throwable) {
                        Log.e("EnhancedVoiceService", "Command STT request failed", t)
                        audioFile.delete()
                    }
                })
                
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error in command transcription", e)
            audioFile.delete()
        }
    }

    private fun createTempAudioFile(audioData: ShortArray): File? {
        return try {
            val tempFile = File.createTempFile("aura_voice", ".wav", cacheDir)
            convertPcmToWav(audioData, tempFile)
            tempFile
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error creating temp audio file", e)
            null
        }
    }

    private fun convertPcmToWav(pcmData: ShortArray, outputFile: File) {
        try {
            val totalAudioLen = pcmData.size * 2 // 16-bit = 2 bytes per sample
            val totalDataLen = totalAudioLen + 36
            val byteRate = SAMPLE_RATE * 2 // 16-bit mono
            
            FileOutputStream(outputFile).use { out ->
                // WAV header
                out.write("RIFF".toByteArray())
                out.write(intToByteArray(totalDataLen))
                out.write("WAVE".toByteArray())
                out.write("fmt ".toByteArray())
                out.write(intToByteArray(16)) // PCM format
                out.write(shortToByteArray(1)) // Audio format (PCM)
                out.write(shortToByteArray(1)) // Number of channels (mono)
                out.write(intToByteArray(SAMPLE_RATE))
                out.write(intToByteArray(byteRate))
                out.write(shortToByteArray(2)) // Block align
                out.write(shortToByteArray(16)) // Bits per sample
                out.write("data".toByteArray())
                out.write(intToByteArray(totalAudioLen))
                
                // Audio data
                for (sample in pcmData) {
                    out.write(shortToByteArray(sample.toShort()))
                }
            }
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error converting PCM to WAV", e)
        }
    }

    private fun intToByteArray(value: Int): ByteArray {
        return byteArrayOf(
            (value and 0xff).toByte(),
            ((value shr 8) and 0xff).toByte(),
            ((value shr 16) and 0xff).toByte(),
            ((value shr 24) and 0xff).toByte()
        )
    }

    private fun shortToByteArray(value: Short): ByteArray {
        return byteArrayOf(
            (value.toInt() and 0xff).toByte(),
            ((value.toInt() shr 8) and 0xff).toByte()
        )
    }

    private fun loadApiKey(): String {
        return try {
            assets.open("api_key.txt").bufferedReader().use { it.readText().trim() }
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Failed to load API key", e)
            ""
        }
    }

    private fun broadcastListeningState(isListening: Boolean, listeningType: String) {
        val intent = Intent(ACTION_LISTENING_STATE).apply {
            putExtra(EXTRA_IS_LISTENING, isListening)
            putExtra(EXTRA_LISTENING_TYPE, listeningType)
        }
        sendBroadcast(intent)
    }

    private fun broadcastAudioLevel(level: Int) {
        val intent = Intent(ACTION_AUDIO_LEVEL).apply {
            putExtra(EXTRA_AUDIO_LEVEL, level)
        }
        sendBroadcast(intent)
    }
}

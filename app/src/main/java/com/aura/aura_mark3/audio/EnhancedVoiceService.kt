// Generated by Copilot
package com.aura.aura_mark3.audio

import android.annotation.SuppressLint
import android.app.Notification
import android.app.NotificationChannel
import android.app.NotificationManager
import android.app.Service
import android.content.Intent
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.os.Build
import android.os.Handler
import android.os.IBinder
import android.os.Looper
import android.util.Log
import androidx.core.app.NotificationCompat
import com.aura.aura_mark3.ai.GroqSttApi
import com.aura.aura_mark3.ai.SttResponse
import com.aura.aura_mark3.ai.provideGroqSttApi
import okhttp3.MediaType.Companion.toMediaTypeOrNull
import okhttp3.MultipartBody
import okhttp3.RequestBody.Companion.asRequestBody
import okhttp3.RequestBody.Companion.toRequestBody
import retrofit2.Call
import retrofit2.Callback
import retrofit2.Response
import java.io.File
import java.io.FileOutputStream
import java.util.concurrent.atomic.AtomicBoolean
import kotlin.math.sqrt

/**
 * Enhanced Voice Service with Continuous Listening and Wake Word Detection
 * 
 * Features:
 * - Continuous audio monitoring for "Hey Aura" wake word
 * - Voice Activity Detection (VAD) for efficient processing
 * - Automatic transcription when voice is detected
 * - Low power consumption with smart audio buffering
 * - Real-time audio level monitoring
 */
class EnhancedVoiceService : Service() {

    companion object {
        const val CHANNEL_ID = "AURA_VOICE_SERVICE"
        const val NOTIFICATION_ID = 2
        const val SAMPLE_RATE = 16000
        const val AUDIO_SOURCE = MediaRecorder.AudioSource.MIC
        const val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO
        const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        
        // Wake word detection parameters
        const val WAKE_WORD_TIMEOUT_MS = 5000L // 5 seconds to detect wake word
        const val VOICE_TIMEOUT_MS = 3000L     // 3 seconds of silence to stop recording
        const val AUDIO_LEVEL_THRESHOLD = 8000 // Higher threshold to reduce false positives
        const val VOICE_CONFIRMATION_FRAMES = 3 // Require multiple frames above threshold
        const val NOISE_FLOOR = 1000 // Background noise level
        
        // Intent actions
        const val ACTION_WAKE_WORD_DETECTED = "com.aura.aura_mark3.WAKE_WORD_DETECTED"
        const val ACTION_VOICE_TRANSCRIPTION = "com.aura.aura_mark3.VOICE_TRANSCRIPTION"
        const val ACTION_LISTENING_STATE = "com.aura.aura_mark3.LISTENING_STATE"
        const val ACTION_AUDIO_LEVEL = "com.aura.aura_mark3.AUDIO_LEVEL"
        
        // Intent extras
        const val EXTRA_TRANSCRIPTION = "transcription"
        const val EXTRA_IS_LISTENING = "is_listening"
        const val EXTRA_AUDIO_LEVEL = "audio_level"
        const val EXTRA_LISTENING_TYPE = "listening_type" // "wake_word" or "command"
    }

    private var audioRecord: AudioRecord? = null
    private var recordingThread: Thread? = null
    private val isRunning = AtomicBoolean(false)
    private val isListeningForWakeWord = AtomicBoolean(true)
    private val isRecordingCommand = AtomicBoolean(false)
    
    private var currentAudioLevel = 0
    private var lastVoiceDetectedTime = 0L
    private var wakeWordDetectedTime = 0L
    private var lastSttRequestTime = 0L
    private val STT_REQUEST_COOLDOWN = 2000L // 2 seconds between STT requests
    
    private val audioBuffer = mutableListOf<Short>()
    private val maxBufferSize = SAMPLE_RATE * 10 // 10 seconds of audio
    
    private val mainHandler = Handler(Looper.getMainLooper())
    private val sttApi = provideGroqSttApi()
    
    // Audio processing variables
    private var silenceCounter = 0
    private val maxSilenceFrames = (VOICE_TIMEOUT_MS / 100).toInt() // 100ms frames
    private var voiceConfirmationCounter = 0
    private var backgroundNoiseLevel = NOISE_FLOOR
    private var adaptiveThreshold = AUDIO_LEVEL_THRESHOLD
    private val recentAudioLevels = mutableListOf<Int>()
    private val maxRecentLevels = 50 // Track last 50 audio levels for noise estimation
    
    override fun onCreate() {
        super.onCreate()
        createNotificationChannel()
        Log.i("EnhancedVoiceService", "Enhanced Voice Service created")
    }

    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int {
        if (!isRunning.get()) {
            startContinuousListening()
        }
        return START_STICKY
    }

    override fun onDestroy() {
        super.onDestroy()
        stopContinuousListening()
        Log.i("EnhancedVoiceService", "Enhanced Voice Service destroyed")
    }

    override fun onBind(intent: Intent?): IBinder? = null

    @SuppressLint("ObsoleteSdkInt")
    private fun createNotificationChannel() {
        val channel = NotificationChannel(
            CHANNEL_ID,
            "AURA Voice Assistant",
            NotificationManager.IMPORTANCE_LOW
        ).apply {
            description = "Continuous voice monitoring for Hey Aura wake word"
            setSound(null, null)
            enableVibration(false)
        }
        
        val notificationManager = getSystemService(NotificationManager::class.java)
        notificationManager?.createNotificationChannel(channel)
    }

    private fun buildNotification(isListening: Boolean, listeningType: String): Notification {
        val title = when {
            isListening && listeningType == "wake_word" -> "🎤 Listening for 'Hey Aura'"
            isListening && listeningType == "command" -> "🗣️ Recording your command"
            else -> "😴 Voice assistant ready"
        }
        
        return NotificationCompat.Builder(this, CHANNEL_ID)
            .setContentTitle("AURA Voice Assistant")
            .setContentText(title)
            .setSmallIcon(android.R.drawable.ic_btn_speak_now)
            .setOngoing(true)
            .setSilent(true)
            .build()
    }

    @SuppressLint("MissingPermission")
    private fun startContinuousListening() {
        if (isRunning.get()) {
            Log.w("EnhancedVoiceService", "Service already running")
            return
        }
        
        // Check permissions first
        if (checkSelfPermission(android.Manifest.permission.RECORD_AUDIO) != android.content.pm.PackageManager.PERMISSION_GRANTED) {
            Log.e("EnhancedVoiceService", "RECORD_AUDIO permission not granted")
            broadcastListeningState(false, "stopped")
            return
        }
        
        try {
            val bufferSize = AudioRecord.getMinBufferSize(
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT
            ) * 2
            
            if (bufferSize <= 0) {
                Log.e("EnhancedVoiceService", "Invalid buffer size: $bufferSize")
                return
            }
            
            audioRecord = AudioRecord(
                AUDIO_SOURCE,
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT,
                bufferSize
            )
            
            if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
                Log.e("EnhancedVoiceService", "AudioRecord initialization failed, state: ${audioRecord?.state}")
                audioRecord?.release()
                audioRecord = null
                broadcastListeningState(false, "stopped")
                return
            }
            
            isRunning.set(true)
            audioRecord?.startRecording()
            
            // Verify recording started
            if (audioRecord?.recordingState != AudioRecord.RECORDSTATE_RECORDING) {
                Log.e("EnhancedVoiceService", "AudioRecord failed to start recording, state: ${audioRecord?.recordingState}")
                stopContinuousListening()
                return
            }
            
            // Start with wake word listening notification
            startForeground(NOTIFICATION_ID, buildNotification(true, "wake_word"))
            broadcastListeningState(true, "wake_word")
            
            recordingThread = Thread { processAudioStream() }.apply { start() }
            
            Log.i("EnhancedVoiceService", "Continuous listening started successfully")
            
        } catch (e: SecurityException) {
            Log.e("EnhancedVoiceService", "Security exception in startContinuousListening", e)
            broadcastListeningState(false, "stopped")
            stopContinuousListening()
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Failed to start continuous listening", e)
            broadcastListeningState(false, "stopped")
            stopContinuousListening()
        }
    }

    private fun stopContinuousListening() {
        isRunning.set(false)
        isListeningForWakeWord.set(false)
        isRecordingCommand.set(false)
        
        try {
            audioRecord?.stop()
            audioRecord?.release()
            audioRecord = null
            
            recordingThread?.interrupt()
            recordingThread = null
            
            audioBuffer.clear()
            
            broadcastListeningState(false, "stopped")
            Log.i("EnhancedVoiceService", "Continuous listening stopped")
            
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error stopping continuous listening", e)
        }
    }

    private fun processAudioStream() {
        val buffer = ShortArray(1024)
        
        while (isRunning.get() && audioRecord?.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
            try {
                val bytesRead = audioRecord?.read(buffer, 0, buffer.size) ?: -1
                
                if (bytesRead > 0) {
                    val audioLevel = calculateAudioLevel(buffer, bytesRead)
                    currentAudioLevel = audioLevel
                    
                    // Broadcast audio level for UI feedback
                    broadcastAudioLevel(audioLevel)
                    
                    // Process based on current state
                    when {
                        isListeningForWakeWord.get() -> {
                            processWakeWordDetection(buffer, bytesRead, audioLevel)
                        }
                        isRecordingCommand.get() -> {
                            processCommandRecording(buffer, bytesRead, audioLevel)
                        }
                    }
                }
                
                Thread.sleep(10) // Small delay to prevent excessive CPU usage
                
            } catch (e: InterruptedException) {
                break
            } catch (e: Exception) {
                Log.e("EnhancedVoiceService", "Error in audio processing", e)
                break
            }
        }
    }

    private fun calculateAudioLevel(buffer: ShortArray, length: Int): Int {
        var sum = 0.0
        for (i in 0 until length) {
            sum += (buffer[i] * buffer[i]).toDouble()
        }
        return sqrt(sum / length).toInt()
    }
    
    private fun updateNoiseEstimation(audioLevel: Int) {
        recentAudioLevels.add(audioLevel)
        if (recentAudioLevels.size > maxRecentLevels) {
            recentAudioLevels.removeAt(0)
        }
        
        // Update background noise level (average of lowest 30% of recent levels)
        if (recentAudioLevels.size >= 10) {
            val sorted = recentAudioLevels.sorted()
            val noiseCount = (sorted.size * 0.3).toInt()
            backgroundNoiseLevel = sorted.take(noiseCount).average().toInt()
            
            // Adaptive threshold: noise level + margin
            adaptiveThreshold = maxOf(AUDIO_LEVEL_THRESHOLD, backgroundNoiseLevel * 3)
        }
    }
    
    private fun isValidVoiceActivity(audioLevel: Int): Boolean {
        updateNoiseEstimation(audioLevel)
        
        val isAboveThreshold = audioLevel > adaptiveThreshold
        
        if (isAboveThreshold) {
            voiceConfirmationCounter++
        } else {
            voiceConfirmationCounter = 0
        }
        
        // Require sustained voice activity to reduce false positives
        return voiceConfirmationCounter >= VOICE_CONFIRMATION_FRAMES
    }

    private fun processWakeWordDetection(buffer: ShortArray, length: Int, audioLevel: Int) {
        if (isValidVoiceActivity(audioLevel)) {
            // Valid voice detected, add to buffer
            for (i in 0 until length) {
                audioBuffer.add(buffer[i])
            }
            
            // Maintain buffer size
            while (audioBuffer.size > maxBufferSize) {
                audioBuffer.removeAt(0)
            }
            
            lastVoiceDetectedTime = System.currentTimeMillis()
            
            // Check if we have enough audio for wake word detection (at least 2 seconds)
            if (audioBuffer.size >= SAMPLE_RATE * 2) {
                checkForWakeWord()
            }
        } else {
            // Silence or noise detected, check timeout
            if (audioBuffer.isNotEmpty() && 
                System.currentTimeMillis() - lastVoiceDetectedTime > 2000) { // Increased to 2 seconds
                // Clear buffer after silence
                audioBuffer.clear()
                voiceConfirmationCounter = 0
                Log.d("EnhancedVoiceService", "Cleared audio buffer due to silence timeout")
            }
        }
    }

    private fun processCommandRecording(buffer: ShortArray, length: Int, audioLevel: Int) {
        if (isValidVoiceActivity(audioLevel)) {
            // Valid voice detected, add to buffer
            for (i in 0 until length) {
                audioBuffer.add(buffer[i])
            }
            lastVoiceDetectedTime = System.currentTimeMillis()
            silenceCounter = 0
        } else {
            // Silence detected
            silenceCounter++
            
            if (silenceCounter >= maxSilenceFrames) {
                // End of command detected
                finishCommandRecording()
            }
        }
    }

    private fun checkForWakeWord() {
        if (audioBuffer.isEmpty()) return
        
        // Simple wake word detection based on audio patterns
        // In a production app, you'd use a more sophisticated wake word detection library
        val audioData = audioBuffer.toShortArray()
        
        // Convert to WAV and check with STT for "hey aura" or similar patterns
        val tempFile = createTempAudioFile(audioData)
        if (tempFile != null) {
            transcribeForWakeWord(tempFile)
        }
        
        // Clear buffer after processing
        audioBuffer.clear()
    }

    private fun transcribeForWakeWord(audioFile: File) {
        try {
            // Rate limiting to prevent 429 errors
            val currentTime = System.currentTimeMillis()
            if (currentTime - lastSttRequestTime < STT_REQUEST_COOLDOWN) {
                Log.d("EnhancedVoiceService", "STT request rate limited, skipping")
                audioFile.delete()
                return
            }
            lastSttRequestTime = currentTime
            val apiKey = loadApiKey()
            if (apiKey.isBlank()) {
                Log.e("EnhancedVoiceService", "API key not found")
                return
            }
            
            val fileBody = audioFile.asRequestBody("audio/wav".toMediaTypeOrNull())
            val filePart = MultipartBody.Part.createFormData("file", audioFile.name, fileBody)
            val modelBody = "whisper-large-v3-turbo".toRequestBody("text/plain".toMediaTypeOrNull())
            
            sttApi.transcribeAudio("Bearer $apiKey", filePart, modelBody)
                .enqueue(object : Callback<SttResponse> {
                    override fun onResponse(call: Call<SttResponse>, response: Response<SttResponse>) {
                        if (response.isSuccessful) {
                            val transcription = response.body()?.text?.lowercase() ?: ""
                            Log.i("EnhancedVoiceService", "Wake word check: $transcription")
                            
                            // Check for wake words with broader patterns
                            if (transcription.contains("hey aura") || 
                                transcription.contains("aura") ||
                                transcription.contains("hey ora") ||
                                transcription.contains("hey aira") ||
                                transcription.contains("hey there") ||
                                transcription.contains("hey") ||
                                transcription.contains("hello") ||
                                transcription.length > 10) { // Any substantial speech
                                
                                Log.i("EnhancedVoiceService", "Wake word pattern detected: '$transcription'")
                                onWakeWordDetected()
                            } else {
                                Log.d("EnhancedVoiceService", "No wake word in: '$transcription'")
                            }
                        } else {
                            val errorCode = response.code()
                            Log.e("EnhancedVoiceService", "STT failed: $errorCode")
                            
                            // Handle rate limiting gracefully
                            if (errorCode == 429) {
                                Log.w("EnhancedVoiceService", "Rate limited - will retry later")
                                lastSttRequestTime = System.currentTimeMillis() + 5000L // Extra cooldown
                            }
                        }
                        audioFile.delete()
                    }
                    
                    override fun onFailure(call: Call<SttResponse>, t: Throwable) {
                        Log.e("EnhancedVoiceService", "STT request failed", t)
                        audioFile.delete()
                    }
                })
                
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error in wake word transcription", e)
            audioFile.delete()
        }
    }

    private fun onWakeWordDetected() {
        Log.i("EnhancedVoiceService", "Wake word 'Hey Aura' detected!")
        
        // Switch to command recording mode
        isListeningForWakeWord.set(false)
        isRecordingCommand.set(true)
        wakeWordDetectedTime = System.currentTimeMillis()
        audioBuffer.clear()
        silenceCounter = 0
        
        // Update notification
        mainHandler.post {
            startForeground(NOTIFICATION_ID, buildNotification(true, "command"))
            broadcastListeningState(true, "command")
            
            // Broadcast wake word detection
            val intent = Intent(ACTION_WAKE_WORD_DETECTED).apply {
                setPackage(packageName)
            }
            sendBroadcast(intent)
        }
    }

    private fun finishCommandRecording() {
        if (!isRecordingCommand.get()) return
        
        isRecordingCommand.set(false)
        
        Log.i("EnhancedVoiceService", "Command recording finished")
        
        if (audioBuffer.isNotEmpty()) {
            val audioData = audioBuffer.toShortArray()
            val tempFile = createTempAudioFile(audioData)
            
            if (tempFile != null) {
                transcribeCommand(tempFile)
            }
        }
        
        // Return to wake word listening
        audioBuffer.clear()
        isListeningForWakeWord.set(true)
        
        mainHandler.post {
            startForeground(NOTIFICATION_ID, buildNotification(true, "wake_word"))
            broadcastListeningState(true, "wake_word")
        }
    }

    private fun transcribeCommand(audioFile: File) {
        try {
            val apiKey = loadApiKey()
            if (apiKey.isBlank()) {
                Log.e("EnhancedVoiceService", "API key not found")
                audioFile.delete()
                return
            }
            
            val fileBody = audioFile.asRequestBody("audio/wav".toMediaTypeOrNull())
            val filePart = MultipartBody.Part.createFormData("file", audioFile.name, fileBody)
            val modelBody = "whisper-large-v3-turbo".toRequestBody("text/plain".toMediaTypeOrNull())
            
            sttApi.transcribeAudio("Bearer $apiKey", filePart, modelBody)
                .enqueue(object : Callback<SttResponse> {
                    override fun onResponse(call: Call<SttResponse>, response: Response<SttResponse>) {
                        if (response.isSuccessful) {
                            val transcription = response.body()?.text ?: ""
                            Log.i("EnhancedVoiceService", "Command transcription: $transcription")
                            
                            if (transcription.isNotBlank()) {
                                // Broadcast transcription
                                val intent = Intent(ACTION_VOICE_TRANSCRIPTION).apply {
                                    putExtra(EXTRA_TRANSCRIPTION, transcription)
                                    setPackage(packageName)
                                }
                                sendBroadcast(intent)
                            }
                        } else {
                            Log.e("EnhancedVoiceService", "Command STT failed: ${response.code()}")
                        }
                        audioFile.delete()
                    }
                    
                    override fun onFailure(call: Call<SttResponse>, t: Throwable) {
                        Log.e("EnhancedVoiceService", "Command STT request failed", t)
                        audioFile.delete()
                    }
                })
                
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error in command transcription", e)
            audioFile.delete()
        }
    }

    private fun broadcastAudioLevel(audioLevel: Int) {
        val intent = Intent(ACTION_AUDIO_LEVEL).apply {
            putExtra(EXTRA_AUDIO_LEVEL, audioLevel)
            setPackage(packageName)
        }
        sendBroadcast(intent)
    }

    private fun broadcastListeningState(isListening: Boolean, listeningType: String) {
        val intent = Intent(ACTION_LISTENING_STATE).apply {
            putExtra(EXTRA_IS_LISTENING, isListening)
            putExtra(EXTRA_LISTENING_TYPE, listeningType)
            setPackage(packageName)
        }
        sendBroadcast(intent)
    }

    // Fix the createTempAudioFile method
    private fun createTempAudioFile(audioData: ShortArray): File? {
        return try {
            val tempFile = File.createTempFile("aura_voice", ".wav", cacheDir)
            
            // Convert short array to WAV format
            val byteData = mutableListOf<Byte>()
            for (sample in audioData) {
                val bytes = shortToByteArray(sample)
                byteData.addAll(bytes.toList())
            }
            
            val totalAudioLen = byteData.size.toLong()
            val totalDataLen = totalAudioLen + 36
            val sampleRate = SAMPLE_RATE
            val channels = 1
            val byteRate = 16 * sampleRate * channels / 8
            
            FileOutputStream(tempFile).use { fos ->
                // Write WAV header
                fos.write(createWavHeader(totalAudioLen, totalDataLen, sampleRate, channels, byteRate))
                // Write audio data
                fos.write(byteData.toByteArray())
            }
            
            tempFile
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Error creating temp audio file", e)
            null
        }
    }

    private fun createWavHeader(
        totalAudioLen: Long,
        totalDataLen: Long,
        sampleRate: Int,
        channels: Int,
        byteRate: Int
    ): ByteArray {
        val header = ByteArray(44)
        header[0] = 'R'.code.toByte()
        header[1] = 'I'.code.toByte()
        header[2] = 'F'.code.toByte()
        header[3] = 'F'.code.toByte()
        header[4] = (totalDataLen and 0xff).toByte()
        header[5] = ((totalDataLen shr 8) and 0xff).toByte()
        header[6] = ((totalDataLen shr 16) and 0xff).toByte()
        header[7] = ((totalDataLen shr 24) and 0xff).toByte()
        header[8] = 'W'.code.toByte()
        header[9] = 'A'.code.toByte()
        header[10] = 'V'.code.toByte()
        header[11] = 'E'.code.toByte()
        header[12] = 'f'.code.toByte()
        header[13] = 'm'.code.toByte()
        header[14] = 't'.code.toByte()
        header[15] = ' '.code.toByte()
        header[16] = 16
        header[17] = 0
        header[18] = 0
        header[19] = 0
        header[20] = 1
        header[21] = 0
        header[22] = channels.toByte()
        header[23] = 0
        header[24] = (sampleRate and 0xff).toByte()
        header[25] = ((sampleRate shr 8) and 0xff).toByte()
        header[26] = ((sampleRate shr 16) and 0xff).toByte()
        header[27] = ((sampleRate shr 24) and 0xff).toByte()
        header[28] = (byteRate and 0xff).toByte()
        header[29] = ((byteRate shr 8) and 0xff).toByte()
        header[30] = ((byteRate shr 16) and 0xff).toByte()
        header[31] = ((byteRate shr 24) and 0xff).toByte()
        header[32] = (channels * 16 / 8).toByte()
        header[33] = 0
        header[34] = 16
        header[35] = 0
        header[36] = 'd'.code.toByte()
        header[37] = 'a'.code.toByte()
        header[38] = 't'.code.toByte()
        header[39] = 'a'.code.toByte()
        header[40] = (totalAudioLen and 0xff).toByte()
        header[41] = ((totalAudioLen shr 8) and 0xff).toByte()
        header[42] = ((totalAudioLen shr 16) and 0xff).toByte()
        header[43] = ((totalAudioLen shr 24) and 0xff).toByte()
        return header
    }

    private fun shortToByteArray(value: Short): ByteArray {
        return byteArrayOf(
            (value.toInt() and 0x00FF).toByte(),
            ((value.toInt() and 0xFF00) shr 8).toByte()
        )
    }

    private fun loadApiKey(): String {
        // Try environment variable first
        val envKey = System.getenv("GROQ_API_KEY")
        if (!envKey.isNullOrBlank()) {
            return envKey
        }
        // Fallback to properties file
        return try {
            val properties = java.util.Properties()
            assets.open("api_keys.properties").use {
                properties.load(it)
            }
            properties.getProperty("groq_api_key", "")
        } catch (e: Exception) {
            Log.e("EnhancedVoiceService", "Failed to load API key", e)
            ""
        }
    }
}
